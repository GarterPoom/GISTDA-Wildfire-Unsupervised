{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GISTDA Wildfire Unsupervised Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sentinel-2 Zip Extraction and JP2 File Processing**\n",
    "This Jupyter Notebook describes the Python script for extracting Sentinel-2 zip files and processing JP2 images efficiently.\n",
    "\n",
    "This script automates:\n",
    "1. Extracting Sentinel-2 zip files while maintaining correct folder structures.\n",
    "2. Extracting and organizing the highest-resolution **JP2** images for bands **(B01â€“B12, B8A)**.\n",
    "3. Copying the **Scene Classification Layer (SCL)** files at **20m resolution**.\n",
    "4. Handling nested folder issues that occur in `.SAFE` structures.\n",
    "5. Enabling **long-path support** on Windows to avoid file path limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s: %(message)s',\n",
    "                    handlers=[logging.StreamHandler()])\n",
    "\n",
    "def extract_zips(root_folder):\n",
    "    \"\"\"\n",
    "    Extract zip files ensuring original folder name is maintained.\n",
    "    \n",
    "    Args:\n",
    "        root_folder (str): Path to the root folder containing zip files.\n",
    "    \"\"\"\n",
    "    root_folder = os.path.abspath(root_folder)\n",
    "\n",
    "    if not os.path.exists(root_folder):\n",
    "        logging.error(f\"Root folder does not exist: {root_folder}\")\n",
    "        return\n",
    "\n",
    "    zip_files = [f for f in os.listdir(root_folder) if f.lower().endswith('.zip')]\n",
    "\n",
    "    if not zip_files:\n",
    "        logging.warning(\"No zip files found in the directory.\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"Found {len(zip_files)} zip file(s) to extract.\")\n",
    "\n",
    "    for zip_filename in zip_files:\n",
    "        try:\n",
    "            zip_path = os.path.join(root_folder, zip_filename)\n",
    "            extract_folder_name = os.path.splitext(zip_filename)[0]\n",
    "            extract_folder = os.path.join(root_folder, extract_folder_name)\n",
    "\n",
    "            if os.path.exists(extract_folder):\n",
    "                logging.warning(f\"Folder {extract_folder_name} already exists. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            os.makedirs(extract_folder, exist_ok=True)\n",
    "\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                extracted_files = zip_ref.namelist()\n",
    "\n",
    "                # Check if archive contains a nested .SAFE folder\n",
    "                has_nested_safe = any(f.startswith(extract_folder_name + '/') for f in extracted_files)\n",
    "\n",
    "                if has_nested_safe:\n",
    "                    zip_ref.extractall(root_folder)  # Extract at root level\n",
    "                else:\n",
    "                    zip_ref.extractall(extract_folder)  # Extract inside a new folder\n",
    "\n",
    "            logging.info(f\"Successfully extracted {zip_filename} to {extract_folder_name}\")\n",
    "\n",
    "        except zipfile.BadZipFile:\n",
    "            logging.error(f\"Corrupt zip file: {zip_filename}\")\n",
    "        except PermissionError:\n",
    "            logging.error(f\"Permission denied when extracting: {zip_filename}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error extracting {zip_filename}: {e}\")\n",
    "\n",
    "def extract_jp2_files(root_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Extract the highest resolution Sentinel-2 JP2 files (Bands 1 to 12, including Band 8A)\n",
    "    and SCL files at 20m resolution.\n",
    "\n",
    "    Args:\n",
    "        root_folder (str): Path to the root folder containing extracted .SAFE folders.\n",
    "        output_folder (str): Path to the folder where JP2 files will be saved.\n",
    "    \"\"\"\n",
    "    root_folder = os.path.abspath(root_folder)\n",
    "    output_folder = os.path.abspath(output_folder)\n",
    "\n",
    "    if not os.path.exists(root_folder):\n",
    "        logging.error(f\"Root folder does not exist: {root_folder}\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    resolution_priority = ['R10m', 'R20m', 'R60m']\n",
    "    jp2_files = {}\n",
    "    scl_files = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        resolution = next((res for res in resolution_priority if root.endswith(res)), None)\n",
    "        if not resolution:\n",
    "            continue\n",
    "\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.jp2'):\n",
    "                try:\n",
    "                    parts = file.split('_')\n",
    "                    if len(parts) < 2:\n",
    "                        continue\n",
    "\n",
    "                    band_identifier = parts[-2]\n",
    "                    granule_id = parts[0] + \"_\" + parts[1]\n",
    "\n",
    "                    if band_identifier == 'SCL' and resolution == 'R20m':\n",
    "                        scl_files[granule_id] = (resolution, root, file)\n",
    "                        continue\n",
    "\n",
    "                    if band_identifier.startswith('B') and (\n",
    "                        band_identifier[1:].isdigit() or band_identifier[1:] == '8A'\n",
    "                    ):\n",
    "                        band_number = band_identifier[1:]\n",
    "\n",
    "                        key = (granule_id, band_number)\n",
    "                        if key not in jp2_files or resolution_priority.index(resolution) < resolution_priority.index(jp2_files[key][0]):\n",
    "                            jp2_files[key] = (resolution, root, file)\n",
    "\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "    processed_granules = set()\n",
    "\n",
    "    for (granule_id, band_number), (_, root, file) in jp2_files.items():\n",
    "        try:\n",
    "            granule_output_folder = os.path.join(output_folder, granule_id)\n",
    "            os.makedirs(granule_output_folder, exist_ok=True)\n",
    "\n",
    "            source_path = os.path.join(root, file)\n",
    "            destination_path = os.path.join(granule_output_folder, file)\n",
    "\n",
    "            shutil.copy2(source_path, destination_path)\n",
    "            logging.info(f\"Copied {file} (Band {band_number}) to {granule_output_folder}\")\n",
    "            \n",
    "            processed_granules.add(granule_id)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error copying file {file}: {e}\")\n",
    "\n",
    "    for granule_id, (resolution, root, file) in scl_files.items():\n",
    "        try:\n",
    "            if granule_id in processed_granules:\n",
    "                granule_output_folder = os.path.join(output_folder, granule_id)\n",
    "\n",
    "                source_path = os.path.join(root, file)\n",
    "                destination_path = os.path.join(granule_output_folder, file)\n",
    "\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "                logging.info(f\"Copied {file} (SCL at 20m) to {granule_output_folder}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error copying SCL file {file}: {e}\")\n",
    "\n",
    "def enable_long_paths():\n",
    "    \"\"\"\n",
    "    Enables long path support on Windows to avoid issues with paths longer than 260 characters.\n",
    "    \"\"\"\n",
    "    if os.name == 'nt':\n",
    "        import subprocess\n",
    "        try:\n",
    "            subprocess.run('REG ADD HKLM\\\\SYSTEM\\\\CurrentControlSet\\\\Control\\\\FileSystem /v LongPathsEnabled /t REG_DWORD /d 1 /f', shell=True, check=True)\n",
    "            logging.info(\"Long path support enabled on Windows.\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            logging.warning(\"Failed to enable long path support. You may need to run this script as Administrator.\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    current_dir = r'sentinel-2/'  # Folder containing the ZIP files\n",
    "    output_dir = r'Classified_Image/'  # Folder to save extracted JP2 files\n",
    "\n",
    "    enable_long_paths()  # Enable long paths on Windows\n",
    "    extract_zips(current_dir)  # Step 1: Extract all ZIP files\n",
    "    extract_jp2_files(current_dir, output_dir)  # Step 2: Extract JP2 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing\n",
    "\n",
    "### Sentinel-2 Image Processing Script\n",
    "\n",
    "### Overview\n",
    "This script processes Sentinel-2 imagery by resampling bands, calculating spectral indices, and generating a multi-band GeoTIFF. It is designed to handle `.jp2` files and process them into a consolidated raster dataset.\n",
    "\n",
    "### Features\n",
    "- **Resampling:** Uses GDAL to resample images to a target resolution (default: 10m).\n",
    "\n",
    "- **Index Calculation:** Computes key spectral indices:\n",
    "  - **NBR (Normalized Burn Ratio)**\n",
    "  - **NDVI (Normalized Difference Vegetation Index)**\n",
    "  - **NDWI (Normalized Difference Water Index)**\n",
    "  - **NBRSWIR (Modified NBR with SWIR)**\n",
    "\n",
    "- **Automatic Folder Scanning:** Searches for `.jp2` files in subdirectories and processes them.\n",
    "- **Error Handling & Cleanup:** Ensures safe file removal and handles common processing errors.\n",
    "\n",
    "### Required Files and Directories\n",
    "- Input Directory: ```Classified_Image/```\n",
    "    - Contains Sentinel-2 JP2 files for processing.\n",
    "\n",
    "- Output Directory: ```Raster_Classified/```\n",
    "    - The processed images will be stored here.\n",
    "\n",
    "### Expected Sentinel-2 Bands:\n",
    "The script requires the following bands:\n",
    "\n",
    "- **B02 (Blue)**\n",
    "- **B03 (Green)**\n",
    "- **B04 (Red)**\n",
    "- **B05 (Visible and Near Infrared (VNIR))**\n",
    "- **B06 (Visible and Near Infrared (VNIR))**\n",
    "- **B07 (Visible and Near Infrared (VNIR))**\n",
    "- **B08 (Visible and Near Infrared (VNIR))**\n",
    "- **B8A (Visible and Near Infrared (VNIR))**\n",
    "- **B11 (Short Wave Infrared (SWIR))**\n",
    "- **B12 (Short Wave Infrared (SWIR))**\n",
    "\n",
    "These bands should be in .jp2 format within the Classified_Image directory.\n",
    "\n",
    "\n",
    "### Output Files\n",
    "GeoTIFF Raster File: Contains 14 bands:\n",
    "\n",
    "- **B02 (Blue)**\n",
    "- **B03 (Green)**\n",
    "- **B04 (Red)**\n",
    "- **B05 (Visible and Near Infrared (VNIR))**\n",
    "- **B06 (Visible and Near Infrared (VNIR))**\n",
    "- **B07 (Visible and Near Infrared (VNIR))**\n",
    "- **B08 (Visible and Near Infrared (VNIR))**\n",
    "- **B8A (Visible and Near Infrared (VNIR))**\n",
    "- **B11 (Short Wave Infrared (SWIR))**\n",
    "- **B12 (Short Wave Infrared (SWIR))**\n",
    "- **NBR (Normalized Burn Ratio)**\n",
    "- **NDVI (Normalized Difference Vegetation Index)**\n",
    "- **NDWI (Normalized Difference Water Index)**\n",
    "- **NBRSWIR (Modified NBR using SWIR bands)**\n",
    "\n",
    "\n",
    "### Review Output\n",
    "**The processed raster file will be stored in Raster_Classified/. Use GIS tools like QGIS to visualize and analyze the output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from osgeo import gdal\n",
    "from pathlib import Path\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "def setup_logging():\n",
    "    \"\"\"\n",
    "    Set up logging to help diagnose issues.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "def resample_image(input_path, output_path, target_resolution=10):\n",
    "    \"\"\"\n",
    "    Resamples a single image to a target resolution using GDAL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Resampling image: {input_path} to {output_path} at {target_resolution}m resolution.\")\n",
    "        \n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        \n",
    "        # Open the input dataset\n",
    "        src_ds = gdal.Open(input_path)\n",
    "        if not src_ds:\n",
    "            raise ValueError(f\"Could not open {input_path}\")\n",
    "            \n",
    "        # Get the input resolution\n",
    "        gt = src_ds.GetGeoTransform()\n",
    "        input_res = gt[1]  # pixel width\n",
    "        \n",
    "        # Calculate new dimensions\n",
    "        src_xsize = src_ds.RasterXSize\n",
    "        src_ysize = src_ds.RasterYSize\n",
    "        dst_xsize = int(src_xsize * (input_res / target_resolution))\n",
    "        dst_ysize = int(src_ysize * (input_res / target_resolution))\n",
    "\n",
    "        # Create translation options\n",
    "        translate_options = gdal.TranslateOptions(\n",
    "            format='GTiff',\n",
    "            width=dst_xsize,\n",
    "            height=dst_ysize,\n",
    "            resampleAlg=gdal.GRA_NearestNeighbour\n",
    "        )\n",
    "        \n",
    "        # Perform resampling\n",
    "        gdal.Translate(\n",
    "            destName=output_path,\n",
    "            srcDS=src_ds,\n",
    "            options=translate_options\n",
    "        )\n",
    "        \n",
    "        # Close the dataset\n",
    "        src_ds = None\n",
    "        \n",
    "        print(f\"Resampling completed: {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error resampling image {input_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def safe_remove(file_path, max_attempts=5, delay=1):\n",
    "    \"\"\"\n",
    "    Safely remove a file with multiple attempts and delay between attempts.\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    if not file_path.exists():\n",
    "        return True\n",
    "    \n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            file_path.unlink()\n",
    "            return True\n",
    "        except PermissionError:\n",
    "            if attempt < max_attempts - 1:\n",
    "                time.sleep(delay)\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing file {file_path}: {str(e)}\")\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "def calculate_indices(dataset):\n",
    "    \"\"\"\n",
    "    Calculate NBR, NDVI, NDWI, and NBRSWIR indices from the input bands.\n",
    "    \"\"\"\n",
    "    # Read bands into numpy arrays\n",
    "    b3 = dataset.GetRasterBand(2).ReadAsArray().astype(float)  # B03\n",
    "    b4 = dataset.GetRasterBand(3).ReadAsArray().astype(float)  # B04\n",
    "    b8 = dataset.GetRasterBand(7).ReadAsArray().astype(float)  # B08\n",
    "    b8a = dataset.GetRasterBand(8).ReadAsArray().astype(float)  # B8A\n",
    "    b11 = dataset.GetRasterBand(9).ReadAsArray().astype(float)  # B11\n",
    "    b12 = dataset.GetRasterBand(10).ReadAsArray().astype(float)  # B12\n",
    "\n",
    "    # Add small epsilon to avoid division by zero\n",
    "    epsilon = 1e-10\n",
    "\n",
    "    # Calculate indices\n",
    "    # NBR = (B8A-B12)/(B8A+B12)\n",
    "    nbr = np.divide(b8a - b12, b8a + b12 + epsilon, where=(b8a + b12) != 0)\n",
    "    \n",
    "    # NDVI = (B8-B4)/(B8+B4)\n",
    "    ndvi = np.divide(b8 - b4, b8 + b4 + epsilon, where=(b8 + b4) != 0)\n",
    "    \n",
    "    # NDWI = (B3-B8)/(B3+B8)\n",
    "    ndwi = np.divide(b3 - b8, b3 + b8 + epsilon, where=(b3 + b8) != 0)\n",
    "    \n",
    "    # NBRSWIR = (B12-B11) - 0.02/(B12+B11) + 0.1\n",
    "    nbrswir = np.where((b12 + b11) != 0, \n",
    "                      (b12 - b11) - 0.02/np.maximum(b12 + b11, epsilon) + 0.1, \n",
    "                      0)\n",
    "    \n",
    "    return nbr, ndvi, ndwi, nbrswir\n",
    "\n",
    "def process_bands(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Processes Sentinel-2 band files in a given input folder.\n",
    "    \n",
    "    Args:\n",
    "        input_folder (str or Path): Input folder containing JP2 files\n",
    "        output_folder (str or Path): Output folder for band files\n",
    "    \"\"\"\n",
    "    temp_folder = None\n",
    "    try:\n",
    "        print(f\"Processing bands in folder: {input_folder}\")\n",
    "        \n",
    "        input_folder = Path(input_folder)\n",
    "        output_folder = Path(output_folder)\n",
    "        output_folder.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        jp2_files = list(input_folder.glob('*.jp2'))\n",
    "        if not jp2_files:\n",
    "            print(\"No JP2 files found in the input folder.\")\n",
    "            return\n",
    "\n",
    "        temp_folder = output_folder / 'temp'\n",
    "        temp_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        band_paths = {}\n",
    "\n",
    "        # Process only the required bands\n",
    "        required_bands = ['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B11', 'B12']\n",
    "        \n",
    "        for jp2_file in jp2_files:\n",
    "            # Skip if not a required band\n",
    "            if not any(band in jp2_file.name for band in required_bands):\n",
    "                continue\n",
    "                \n",
    "            output_path = temp_folder / f\"{jp2_file.stem}_resampled.tif\"\n",
    "            \n",
    "            if resample_image(str(jp2_file), str(output_path)):\n",
    "                for band in required_bands:\n",
    "                    if band in jp2_file.name:\n",
    "                        band_paths[band] = str(output_path)\n",
    "                        break\n",
    "\n",
    "        # Check if we have all required bands\n",
    "        missing_bands = [band for band in required_bands if band not in band_paths]\n",
    "        if missing_bands:\n",
    "            raise ValueError(f\"Missing required bands: {missing_bands}\")\n",
    "\n",
    "        # Create output filename\n",
    "        sample_filename = jp2_files[0].name\n",
    "        parts = sample_filename.split('_')\n",
    "        tile_date_timestamp = f\"{parts[0]}_{parts[1]}\"\n",
    "        output_filename = f\"{tile_date_timestamp}.tif\"\n",
    "        output_path = output_folder / output_filename\n",
    "\n",
    "        print(f\"Creating output file: {output_path}\")\n",
    "\n",
    "        # Create VRT\n",
    "        vrt_path = str(temp_folder / 'temp.vrt')\n",
    "        ordered_files = [band_paths[band] for band in required_bands]\n",
    "        vrt_ds = gdal.BuildVRT(vrt_path, ordered_files, separate=True)\n",
    "        \n",
    "        if vrt_ds is None:\n",
    "            raise ValueError(\"Failed to create VRT dataset\")\n",
    "\n",
    "        # Calculate indices\n",
    "        nbr, ndvi, ndwi, nbrswir = calculate_indices(vrt_ds)\n",
    "        \n",
    "        # Create output dataset\n",
    "        driver = gdal.GetDriverByName('GTiff')\n",
    "        out_ds = driver.Create(str(output_path), vrt_ds.RasterXSize, vrt_ds.RasterYSize, 14, gdal.GDT_Float32)\n",
    "        \n",
    "        if out_ds is None:\n",
    "            raise ValueError(\"Failed to create output dataset\")\n",
    "\n",
    "        # Copy geotransform and projection\n",
    "        out_ds.SetGeoTransform(vrt_ds.GetGeoTransform())\n",
    "        out_ds.SetProjection(vrt_ds.GetProjection())\n",
    "        \n",
    "        # Write original bands\n",
    "        for i in range(10):\n",
    "            band_data = vrt_ds.GetRasterBand(i + 1).ReadAsArray()\n",
    "            out_ds.GetRasterBand(i + 1).WriteArray(band_data)\n",
    "        \n",
    "        # Write indices\n",
    "        out_ds.GetRasterBand(11).WriteArray(nbr)\n",
    "        out_ds.GetRasterBand(12).WriteArray(ndvi)\n",
    "        out_ds.GetRasterBand(13).WriteArray(ndwi)\n",
    "        out_ds.GetRasterBand(14).WriteArray(nbrswir)\n",
    "        \n",
    "        # Set band descriptions\n",
    "        band_descriptions = ['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', \n",
    "                           'B11', 'B12', 'NBR', 'NDVI', 'NDWI', 'NBRSWIR']\n",
    "        for i, desc in enumerate(band_descriptions, 1):\n",
    "            out_ds.GetRasterBand(i).SetDescription(desc)\n",
    "        \n",
    "        # Close datasets\n",
    "        vrt_ds = None\n",
    "        out_ds = None\n",
    "        \n",
    "        # Clean up temporary files\n",
    "        print(\"Cleaning up temporary files.\")\n",
    "        for file_path in band_paths.values():\n",
    "            safe_remove(file_path)\n",
    "        safe_remove(vrt_path)\n",
    "        \n",
    "        if temp_folder and temp_folder.exists():\n",
    "            try:\n",
    "                temp_folder.rmdir()\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not remove temp folder: {str(e)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing bands: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        # Final cleanup attempt\n",
    "        if temp_folder and temp_folder.exists():\n",
    "            try:\n",
    "                for file in temp_folder.glob('*'):\n",
    "                    safe_remove(file)\n",
    "                temp_folder.rmdir()\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Failed final cleanup: {str(e)}\")\n",
    "\n",
    "def find_and_process_folders(root_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Searches for and processes folders containing .jp2 files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        root_folder = Path(root_folder)\n",
    "        output_folder = Path(output_folder)\n",
    "        \n",
    "        print(f\"Searching for folders in: {root_folder}\")\n",
    "        \n",
    "        processed = False\n",
    "        for dirpath in root_folder.rglob('*'):\n",
    "            if dirpath.is_dir() and any(f.suffix == '.jp2' for f in dirpath.iterdir()):\n",
    "                relative_path = dirpath.relative_to(root_folder)\n",
    "                current_output_folder = output_folder / relative_path\n",
    "                print(f\"Found JP2 files in: {dirpath}. Processing...\")\n",
    "                process_bands(dirpath, current_output_folder)\n",
    "                processed = True\n",
    "        \n",
    "        if not processed:\n",
    "            print(\"No folders with JP2 files were found.\")\n",
    "        else:\n",
    "            print(\"All folders processed.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing folders: {str(e)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def main():\n",
    "    # Configure logging\n",
    "    logger = setup_logging()\n",
    "\n",
    "    try:\n",
    "        # Enable GDAL exceptions\n",
    "        gdal.UseExceptions()\n",
    "        \n",
    "        # Get current working directory\n",
    "        current_dir = Path.cwd()\n",
    "        logger.info(f\"Current working directory: {current_dir}\")\n",
    "\n",
    "        # Check input folders\n",
    "        root_folder = current_dir / 'Classified_Image'\n",
    "        output_folder = current_dir / 'Raster_Classified'\n",
    "\n",
    "        # Check if input folder exists\n",
    "        if not root_folder.exists():\n",
    "            logger.error(f\"Input folder does not exist: {root_folder}\")\n",
    "            logger.info(\"Please create a 'Classified_Image' folder and place Sentinel-2 JP2 files inside.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        # Create output folder if it doesn't exist\n",
    "        output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Find and process JP2 files\n",
    "        jp2_files = list(root_folder.rglob('*.jp2'))\n",
    "        \n",
    "        if not jp2_files:\n",
    "            logger.error(f\"No JP2 files found in {root_folder}\")\n",
    "            logger.info(\"Ensure Sentinel-2 JP2 files are present in the 'Classified_Image' folder.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        logger.info(f\"Found {len(jp2_files)} JP2 files to process\")\n",
    "        \n",
    "        # Run processing\n",
    "        find_and_process_folders(root_folder, output_folder)\n",
    "        \n",
    "        logger.info(\"Processing complete.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error: {str(e)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering\n",
    "\n",
    "This script automates the processing of multiple `.tif` raster files by applying k-means clustering and saving the results. The key components are:\n",
    "\n",
    "## Features\n",
    "- **Automatic File Discovery:** Loops through all `.tif` files in the specified root directory (`Raster_Classified`) and its subdirectories.\n",
    "- **Preprocessing:**\n",
    "  - Reads each raster file using GDAL.\n",
    "  - Extracts multi-band pixel data and reshapes it for clustering.\n",
    "  - Handles missing values by replacing NaNs with zeros.\n",
    "- **Clustering with K-Means:**\n",
    "  - Uses scikit-learn's `KMeans` algorithm to classify pixels into 50 clusters.\n",
    "  - Reshapes the classified data back to the original raster dimensions.\n",
    "- **Saving the Results:**\n",
    "  - Writes the clustered output to GeoTIFF format.\n",
    "  - Preserves geospatial metadata (projection, transformation).\n",
    "  - Saves results in the `clustered_result` directory while maintaining the input folder structure.\n",
    "\n",
    "## How to Use\n",
    "1. Ensure that all required libraries (`numpy`, `matplotlib`, `sklearn`, `gdal`) are installed.\n",
    "2. Place all `.tif` files inside the `Raster_Classified` directory.\n",
    "3. Run the script in a Python environment (e.g., Jupyter Lab).\n",
    "4. The processed images will be saved in the `clustered_result` directory.\n",
    "\n",
    "This approach is useful for large-scale satellite imagery classification, environmental monitoring, and remote sensing applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import cluster\n",
    "from osgeo import gdal, gdal_array\n",
    "\n",
    "# Set the root directory where your .tif files are located\n",
    "root_dir = \"Raster_Classified\"\n",
    "output_dir = \"clustered_result\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
    "\n",
    "# Function to process a single raster file\n",
    "def process_raster(file_path, output_path):\n",
    "    try:\n",
    "        # Open raster file\n",
    "        ds = gdal.Open(file_path, gdal.GA_ReadOnly)\n",
    "        if ds is None:\n",
    "            print(f\"Could not open {file_path}\")\n",
    "            return\n",
    "        \n",
    "        img = np.zeros((ds.RasterYSize, ds.RasterXSize, ds.RasterCount),\n",
    "                       gdal_array.GDALTypeCodeToNumericTypeCode(ds.GetRasterBand(1).DataType))\n",
    "        \n",
    "        for b in range(img.shape[2]):\n",
    "            img[:, :, b] = ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "        \n",
    "        # Reshape for clustering\n",
    "        new_shape = (img.shape[0] * img.shape[1], img.shape[2])\n",
    "        X = img[:, :, :14].reshape(new_shape)\n",
    "        \n",
    "        # Handle NaN values\n",
    "        X_filled = np.nan_to_num(X, nan=0)\n",
    "        \n",
    "        # Apply k-means clustering\n",
    "        k_means = cluster.KMeans(n_clusters=50, max_iter=50, random_state=42)\n",
    "        k_means.fit(X_filled)\n",
    "        X_cluster = k_means.labels_.reshape(img[:, :, 0].shape)\n",
    "        \n",
    "        # Save clustered image\n",
    "        band = ds.GetRasterBand(1)\n",
    "        rows, cols = band.ReadAsArray().shape\n",
    "        driver = gdal.GetDriverByName(\"GTiff\")\n",
    "        out_raster = driver.Create(output_path, cols, rows, 1, gdal.GDT_Byte)\n",
    "        out_raster.SetGeoTransform(ds.GetGeoTransform())\n",
    "        out_raster.SetProjection(ds.GetProjection())\n",
    "        out_raster.GetRasterBand(1).WriteArray(X_cluster)\n",
    "        out_raster.FlushCache()\n",
    "        \n",
    "        del out_raster\n",
    "        del ds\n",
    "\n",
    "        # Plot the clustered results\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(X_cluster, cmap='hsv')\n",
    "        plt.colorbar()\n",
    "        plt.title(\"Clustered Results (HSV Color Map)\")\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Processed and saved: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# Loop through all .tif files in the root directory and subdirectories\n",
    "for subdir, _, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".tif\"):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            relative_path = os.path.relpath(file_path, root_dir)\n",
    "            output_path = os.path.join(output_dir, relative_path)\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Ensure directory exists\n",
    "            process_raster(file_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RIDA_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
